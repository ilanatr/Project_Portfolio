## About this Repo 

This is a portfolio of my work applying fundamental data analytic and data science techniques.
It includes five different code tasks, which are outlined in more detail below.

### 1. Organising and Filtering Datasets

[Organising and Filtering Datasets](https://github.com/ilanatr/Project_Portfolio/blob/main/Data_Filtering_Organising.ipynb)

Objective 1: Develop a Python script that filters and organizes a dataset based on specific criteria.
Output was to filter data by age, name or other characteristic

Requirements:
- Pandas library
- Use dictionary, list or set
- Implement functions that filter data

The file Data_Filtering_Organising includes three key user-defined functions:
1. Reads the dataset and outputs the values associated with a specific key in the dataset
2. Outputs a frequency table for a specified column name
3. Creates a filtered data set just including name and age based on a specific age range

### 2. Rock Paper Scissors Game

[Rock, Paper, Scissors](https://github.com/ilanatr/Project_Portfolio/blob/main/Desc_stats_and_data_viz.ipynb)

Objective:
To create a programme that plays the rock, paper, scissors game which seeks input from the user and a random choice from the computer to determine a winner.

Requirements:
- Random library
- Utilises exception handling to highlight input (value) errors.

### 3. Data visualisation of car data

[Data Visualisation] (https://github.com/ilanatr/Project_Portfolio/blob/main/data_viz_task.ipynb)

Objective:
- To create and interpret simple data visualisations for car manufacturer data

Requirements:
- Pandas library
- Matplotlib.pyplot libray
- NumPy library
- Seaborn library
- Include boxplots, histograms, lineplots and barplots.

### 4. Analyse Customer Data with SQL

[SQL Customer Data Analysis](https://github.com/ilanatr/Project_Portfolio/blob/main/analyse_cust_data_sql.sql)

Objective:
- To analyse the SQL Lite Sakila database which includes data on DVD rental stores globally.
  
Output: The SQL file implements queries to create and read the database in order to calculate information such as total payments and average payment information.

### 5. Data Statistics and Data Visualisation of country CO2 emissions

Objective: carry out exploratory data analysis of CO2 emissions for countries 

Data Source:[Kaggle CO2 emissions: 1960-2019](https://www.kaggle.com/datasets/ulrikthygepedersen/co2-emissions-by-country)

[Country CO2 Emissions EDA](https://github.com/ilanatr/Project_Portfolio/blob/main/Desc_stats_and_data_viz.ipynb)

*****Descriptive Statistics and Data Visualisation Tool*****

Objective: Create a Python script that computes descriptive statistics for a given dataset and visualizes these statistics through various charts and graphs. The tool should help in understanding the distribution, central tendency, and variability of data.

Requirements:
- Use pandas, numpy, matplotlib and seaborn libraries
- Compute basic stats (mean, median, mode, sd, quartiles)
- Create visualisations (hists, boxplots, scatterplots)
- Apply basic inferential stats (e.g. confidence intervals)

This tool  computes descriptive statistics for a dataset on CO2 emissions by countries and visualises these statistics through various charts and graphs. 
The tool helps in understanding the distribution, central tendency, and variability of the data using timeseries analysis.


